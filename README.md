# Desafio T√©cnico: Pipeline de Dados de Lineup Portu√°rio

## üìù Descri√ß√£o do Projeto
Este projeto implementa um pipeline de dados ETL em Python para coletar, processar e agregar diariamente as informa√ß√µes de lineup de navios dos portos de Santos e Paranagu√°. A solu√ß√£o foi projetada para ser resiliente √†s inconsist√™ncias dos dados de origem, utilizando a arquitetura Medallion para garantir a qualidade e a rastreabilidade em cada etapa. O resultado final √© uma base de dados anal√≠tica (Camada Ouro) com os volumes di√°rios movimentados por porto, produto e sentido (importa√ß√£o/exporta√ß√£o).

## üèõÔ∏è Arquitetura
A solu√ß√£o foi desenvolvida utilizando a arquitetura Medallion, que separa o fluxo de dados em tr√™s camadas l√≥gicas:

* **ü•â Camada Bronze:** Cont√©m os dados brutos e imut√°veis, extra√≠dos diretamente das fontes (arquivos HTML com data de extra√ß√£o). Funciona como uma fonte da verdade, permitindo o reprocessamento e a auditoria completa do pipeline.
* **ü•à Camada Silver:** Armazena os dados ap√≥s a consolida√ß√£o das fontes. Nesta camada, os dados ainda refletem as heterogeneidades estruturais de cada porto.
* **ü•á Camada Gold:** Apresenta o produto de dados final. Nesta etapa, a l√≥gica de transforma√ß√£o √© aplicada para limpar, padronizar, deduplicar e agregar os dados em um esquema √∫nico e confi√°vel, pronto para o consumo anal√≠tico.

## üöÄ Como Executar

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/danielfloriani/pipeline_lineup_portuario](https://github.com/danielfloriani/pipeline_lineup_portuario.git)
    cd pipeline_lineup_portuario
    ```
2.  **Crie e ative um ambiente virtual:**
    ```bash
    python -m venv venv
    # No Windows:
    venv\Scripts\activate
    ```
3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Execute o pipeline completo:**
    ```bash
    python pipeline.py
    ```
    Ao final da execu√ß√£o, a tabela anal√≠tica estar√° em `data/gold/volumes_diarios.parquet`.

## ü§î Decis√µes de Projeto e Desafios Superados

O desenvolvimento seguiu uma abordagem iterativa, onde a auditoria cont√≠nua dos resultados guiou as decis√µes de engenharia para aumentar a robustez da solu√ß√£o.

* **Estrat√©gia de Processamento:** A decis√£o inicial de processar todo o hist√≥rico da camada Bronze revelou um desafio cr√≠tico: a duplica√ß√£o de volumes devido a reagendamentos de navios. A arquitetura foi ent√£o refinada para processar apenas a "fotografia" mais recente de cada porto, garantindo que a camada Ouro reflita o estado mais atualizado do lineup.

* **Centraliza√ß√£o da L√≥gica de Limpeza:** Tentativas iniciais de distribuir a l√≥gica de limpeza entre os m√≥dulos de extra√ß√£o criaram inconsist√™ncias dif√≠ceis de depurar. A solu√ß√£o final e mais robusta foi centralizar **toda** a l√≥gica de padroniza√ß√£o, convers√£o de tipos e tratamento de casos espec√≠ficos (como os formatos num√©ricos de Paranagu√°) em um √∫nico m√≥dulo (`gold_processor.py`), garantindo que as regras sejam aplicadas de forma uniforme sobre o conjunto de dados consolidado.

* **Robustez na Convers√£o de Tipos:** A convers√£o de dados textuais para num√©ricos e datas foi um desafio chave. A utiliza√ß√£o de `errors='coerce'` em `pd.to_numeric` e `pd.to_datetime`, combinada com fun√ß√µes de limpeza espec√≠ficas, garantiu que o pipeline n√£o falhasse com dados mal formatados, descartando-os de forma controlada e registrando apenas informa√ß√µes de alta qualidade.

* **Deduplica√ß√£o Inteligente:** Mesmo processando apenas o arquivo mais recente, foi identificado que poderiam existir duplicatas. Foi implementada uma l√≥gica de deduplica√ß√£o baseada em uma chave de neg√≥cio (`imo`, `viagem`, `data_prevista`, `produto`) para assegurar que cada evento de embarque seja representado apenas uma vez no resultado final.

## üîÆ Pr√≥ximos Passos e Melhorias

* **Orquestra√ß√£o:** Integrar o pipeline com um orquestrador de workflows como Airflow ou Prefect para agendamento, monitoramento e retentativas autom√°ticas.
* **Testes Unit√°rios:** Implementar testes formais com `pytest` para as fun√ß√µes de transforma√ß√£o, validando a l√≥gica de limpeza e agrega√ß√£o de forma isolada.
* **Containeriza√ß√£o:** Empacotar a aplica√ß√£o com Docker para garantir a portabilidade e facilitar o deploy em diferentes ambientes.
* **Logging:** Substituir os comandos `print` por um sistema de `logging` mais estruturado para melhor controle e monitoramento dos eventos do pipeline em produ√ß√£o.